{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libary imports\n",
    "import momepy\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import networkx as nx \n",
    "import osmnx as ox\n",
    "from matplotlib import pyplot as plt\n",
    "import pandana as pdna\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start timer\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in edges\n",
    "OSM_edges = gpd.read_file(r'C:\\Users\\b8008458\\Documents\\2021_2022\\Scratch Space\\York\\Bike Network\\bike_network_costs.shp')\n",
    "\n",
    "\n",
    "# read in population weighted centeroids\n",
    "pwc = gpd.read_file(r'C:\\Users\\b8008458\\Documents\\2021_2022\\Scratch Space\\York\\Centriods\\YorkLSOAsReproSingle.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert shapefile to nodes and edges\n",
    "nodes, edges = momepy.nx_to_gdf(momepy.gdf_to_nx(OSM_edges.explode()))\n",
    "nodes = nodes.set_index(\"nodeID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pandana network\n",
    "edges_pdna = pdna.Network(nodes.geometry.x, nodes.geometry.y, edges['node_start'], edges['node_end'], edges[['cost']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a reversed list of population weighted centeroids in order to make a OD list\n",
    "pwc_reversed = pwc.iloc[::-1].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set origins and destinataions\n",
    "origins = edges_pdna.get_node_ids(pwc.geometry.x, pwc.geometry.y).values\n",
    "destinations = edges_pdna.get_node_ids(pwc_reversed.geometry.x, pwc_reversed.geometry.y).values\n",
    "origins_df = pd.DataFrame(origins)\n",
    "destinations_df = pd.DataFrame(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of origins dataframe to allow for joining on index later\n",
    "origins_df['origins_index'] = range(1, len(origins) + 1)\n",
    "origins_df['origins_index'] = origins_df['origins_index'] - 1\n",
    "origins_index_df = origins_df\n",
    "origins_index_df.rename(columns = {0:'Origins'}, inplace = True)\n",
    "\n",
    "# add column of index positions to pwc for index join later\n",
    "pwc['origins_index'] = range(1, len(pwc) + 1)\n",
    "pwc['origins_index'] = pwc['origins_index'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools package\n",
    "# create list of all combinations\n",
    "import itertools\n",
    "OD_pairs = list(itertools.product(origins,destinations))\n",
    "\n",
    "# split into two dataframes\n",
    "OD_pairs_df = pd.DataFrame(OD_pairs, columns =['Origins', 'Destinations'])\n",
    "OD_Origins = OD_pairs_df['Origins']\n",
    "OD_Destinations = OD_pairs_df['Destinations']\n",
    "OD_Origins_Arrary = OD_Origins.to_numpy()\n",
    "OD_Destinations_Arrary = OD_Destinations.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join dataframes back\n",
    "OD_pairs_df = pd.merge(OD_pairs_df, origins_index_df, on='Origins', how='outer')\n",
    "OD_pairs_pwc_join = OD_pairs_df.merge(pwc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# find number of columns in dataframe\n",
    "dataframe_width = OD_pairs_pwc_join.shape[1]\n",
    "\n",
    "# remove rows from the dataframe where no trips are present\n",
    "\n",
    "startPos = 8\n",
    "row_num = 1\n",
    "# counter = 0 \n",
    "\n",
    "for startID in OD_pairs_pwc_join['Origins']:\n",
    "    if OD_pairs_pwc_join.iloc[row_num,startPos] == '0':\n",
    "        OD_pairs_pwc_join.at[row_num,'flag'] = 'True'\n",
    "        OD_pairs_pwc_join.at[row_num,'trips'] = OD_pairs_pwc_join.iloc[row_num,startPos]\n",
    "        row_num = row_num + 1\n",
    "        startPos = startPos + 1\n",
    "    else:\n",
    "        OD_pairs_pwc_join.at[row_num,'flag'] = 'False'\n",
    "        OD_pairs_pwc_join.at[row_num,'trips'] = OD_pairs_pwc_join.iloc[row_num,startPos]\n",
    "        row_num = row_num + 1\n",
    "        startPos = startPos + 1\n",
    "    if startPos == (OD_pairs_pwc_join.shape[1]) - 3:\n",
    "        startPos = 8\n",
    "    if row_num == (OD_pairs_pwc_join.shape[0]) - 1:\n",
    "        row_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where the flag is true\n",
    "OD_pairs_pwc_join.drop(OD_pairs_pwc_join[OD_pairs_pwc_join['flag'] == 'True'].index, inplace=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = OD_pairs_pwc_join\n",
    "# duplicate rows based on the number of trips made\n",
    "sample_df = sample_df.dropna(axis=0)\n",
    "sample_df = sample_df.loc[sample_df.index.repeat(sample_df['trips'])]\n",
    "\n",
    "# reconstruct OD pairs \n",
    "# split into two dataframes\n",
    "OD_pairs_df = pd.DataFrame(sample_df, columns =['Origins', 'Destinations'])\n",
    "OD_pairs = OD_pairs_df.values.tolist()\n",
    "OD_Origins = OD_pairs_df['Origins']\n",
    "OD_Destinations = OD_pairs_df['Destinations']\n",
    "OD_Origins_Arrary = OD_Origins.to_numpy()\n",
    "OD_Destinations_Arrary = OD_Destinations.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all routes and all route distances \n",
    "routes = []\n",
    "distances = []\n",
    "\n",
    "print(\"Starting OD Processing...\")\n",
    "for a,b in OD_pairs:\n",
    "    route = edges_pdna.shortest_paths(OD_Origins_Arrary,OD_Destinations_Arrary)\n",
    "    #routes.append(route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Finished OD Processing\")\n",
    "# create column of combined pairs\n",
    "edges['route_pairs'] = edges['node_start'].astype(str) + ',' + edges['node_end'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe of pairs at each end of a edge\n",
    "route_pairs = []\n",
    "\n",
    "# loop through all routes (as a list) to store all the pair values\n",
    "for route in route:\n",
    "    for i in range(len(route) -1 ):\n",
    "        temp = str(route[i]) + \",\" + str(route[i+1])\n",
    "        route_pairs.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting list into dataframe for comparsion between route pairs and egdes\n",
    "routes_df = pd.DataFrame({'route_pairs':route_pairs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes_df_reversed = routes_df.route_pairs.str.split(pat=',',expand=True)\n",
    "routes_df_reversed = routes_df_reversed.rename(columns= {0:'node_start',1:'node_end'})\n",
    "routes_df_reversed = routes_df_reversed['node_end'] + ',' + routes_df_reversed['node_start']\n",
    "routes_df_reversed = routes_df_reversed.rename(str('route_pairs'), inplace=True)\n",
    "routes_df_reversed = routes_df_reversed.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the number of passes through each edge\n",
    "passes_df = routes_df[routes_df['route_pairs'].isin(edges['route_pairs'])]\n",
    "passes_df.groupby(\"route_pairs\").size().sort_values(ascending=False)\n",
    "passes_output_df = passes_df.groupby(\"route_pairs\").size().reset_index(name=\"Passes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the number of passes through each edge\n",
    "passes_df_reversed = routes_df_reversed[routes_df_reversed['route_pairs'].isin(edges['route_pairs'])]\n",
    "passes_df_reversed.groupby(\"route_pairs\").size().sort_values(ascending=False)\n",
    "passes_output_df_reversed = passes_df_reversed.groupby(\"route_pairs\").size().reset_index(name=\"Passes_reversed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the passes dataframe to the edges dataframe\n",
    "edges = pd.merge(edges, passes_output_df, on ='route_pairs', how = 'left').fillna(0)\n",
    "edges = pd.merge(edges, passes_output_df_reversed, on ='route_pairs', how = 'left').fillna(0)\n",
    "edges['total_passes'] = edges['Passes'] + edges['Passes_reversed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges.to_file(r'C:\\Users\\b8008458\\Documents\\2021_2022\\Scratch Space\\York\\Bike Network\\bike_network_routeuseage.shp')\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Execution time is:\", end-start, \"seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6dd89145d9df3f88584da4faeae77e64fe9e5025a7251d603333dd825c826ca2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
